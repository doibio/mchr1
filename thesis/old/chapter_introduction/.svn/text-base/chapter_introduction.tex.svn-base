
\startfirstchapter{Introduction}
\label{chapter:introduction}

In this work, I will describe work that I have been involved with in
applying advanced audio feature extraction, analysis and visualization
tools to a variety of different problem domains.  These domains
include the study of Orca vocalizations, chant traditions from around
the world, the analysis and visualization of large music collections.

Although these application areas are quite different different, the
tools and techniques that we use to study each of them are very
similar.  There are two distinct types of tools that will be
demonstrated, the first are sets of tools to extract features and
analyze audio.  The second set of tools are web-based tools that allow
users from around the world to collaboratively view and analyze the
results from the first set of tools.

An important part of this work is that it is essential for us to
collaborate with domain experts, and a large amount of the effort in
this project is devoted to interfaces that allow domain experts with
varying degrees of computer sophistication to access and make sense of
the extracted data that our tools produce.  Thus, the core part of
this work is to bring together tools, data and scientists together
into a highly effective collaborative team.


\section{Motivation}

Web-based software has been helping connect communities of researchers
since its inception.  Recently, advances in software and in computer
power have dramatically widened its possible applications to include a
wide variety of multimedia content.  These advances have been
primarily in the business community, and the tools developed are just
starting to be used by academics. We have been working on applying
these technologies to ongoing collaborative projects that we are
involved in \cite{sness2008}. By leveraging several new technologies
including \emph{Flash}, \emph{haXe}, \emph{AJAX} and \emph{Ruby on
Rails}, we have been able to rapidly develop web-based tools. Rapid
prototyping and iterative development have been key elements of our
collaborative strategy. Although our number of users is limited
compared to other areas of multimedia analysis and retrieval, this is
to some degree compensated by their passion and willingness to work
closely with us in developing these tools.

\section{Scope of this work}

The fields of Music Information Retrieval (MIR), Visualization and
web-based Human Computer Interaction (HCI) are each vast topics in
their own right, not to mention the application areas of
Ethnomusicology and Bioacoustics, so as to make the present work
tractable, we will focus on three very specific problems and will
apply a carefully selected subset of some of the tools in MIR,
Visualization and HCI to help us in developing solutions for these
areas.

In the field of the analysis of Bioacoustic signals
from \textit{Orcinus Orca} vocalizations, we will use tools from MIR
including Fast Fourier Transforms (FFT) to analyze and display
spectrograms, along with tools such as Mel-Frequency Cepstral
Coefficients (MFCC), average zero crossing rate, and spectral
centroid, along with many other such tools, to help us visualize and
analyze orca vocalizations.  We will be also using techniques from the
fields of Visualization and HCI, including the micro-macro view,
draggable panes, multi-resolution browsing, tagging and the layered
presentation of data.

We will use many of these same tools in the analysis of audio from
chant traditions around the world, and will in addition be using
techniques such as Fundamental Frequency Estimation and Dynamic Time
Warping.

In the area of the analysis of large music collections, we will use
many of the previous tools, including the FFT and MFCC coefficients to
extract features from the songs, and will primarily be using the
technique of Self-Organizing Maps to reduce the dimensionality of the
high dimension spaces created by feature extraction to two dimensions.
